
@misc{hartford_spectrum_2024,
	title = {Spectrum: {Targeted} {Training} on {Signal} to {Noise} {Ratio}},
	shorttitle = {Spectrum},
	url = {http://arxiv.org/abs/2406.06623},
	abstract = {Efficiently post-training large language models remains a challenging task due to the vast computational resources required. We present Spectrum, a method that accelerates LLM training by selectively targeting layer modules based on their signal-to-noise ratio (SNR), and freezing the remaining modules. Our approach, which utilizes an algorithm to compute module SNRs prior to training, has shown to effectively match the performance of full fine-tuning while reducing GPU memory usage. Experiments comparing Spectrum to existing methods such as QLoRA demonstrate its effectiveness in terms of model quality and VRAM efficiency in distributed environments.},
	urldate = {2025-02-03},
	publisher = {arXiv},
	author = {Hartford, Eric and Atkins, Lucas and Neto, Fernando Fernandes and Golchinfar, David},
	month = jun,
	year = {2024},
	note = {arXiv:2406.06623 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/sagar/Zotero/storage/YSTUKB48/2406.html:text/html},
}

@inproceedings{tiwari_using_2024,
	address = {Waikoloa, HI, USA},
	title = {Using {Early} {Readouts} to {Mediate} {Featural} {Bias} in {Distillation}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350318920},
	url = {https://ieeexplore.ieee.org/document/10484228/},
	doi = {10.1109/WACV57701.2024.00262},
	urldate = {2025-02-03},
	booktitle = {2024 {IEEE}/{CVF} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})},
	publisher = {IEEE},
	author = {Tiwari, Rishabh and Sivasubramanian, Durga and Mekala, Anmol and Ramakrishnan, Ganesh and Shenoy, Pradeep},
	month = jan,
	year = {2024},
	pages = {2626--2635},
}

@misc{raman_online_2024,
	title = {Online {Classification} with {Predictions}},
	url = {http://arxiv.org/abs/2405.14066},
	abstract = {We study online classification when the learner has access to predictions about future examples. We design an online learner whose expected regret is never worse than the worst-case regret, gracefully improves with the quality of the predictions, and can be significantly better than the worst-case regret when the predictions of future examples are accurate. As a corollary, we show that if the learner is always guaranteed to observe data where future examples are easily predictable, then online learning can be as easy as transductive online learning. Our results complement recent work in online algorithms with predictions and smoothed online classification, which go beyond a worse-case analysis by using machine-learned predictions and distributional assumptions respectively.},
	urldate = {2025-02-03},
	publisher = {arXiv},
	author = {Raman, Vinod and Tewari, Ambuj},
	month = may,
	year = {2024},
	note = {arXiv:2405.14066 [cs, stat]},
	keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/sagar/Zotero/storage/ZMRIRNBC/2405.html:text/html},
}

@misc{jazbec_early-exit_2024,
	title = {Early-{Exit} {Neural} {Networks} with {Nested} {Prediction} {Sets}},
	url = {http://arxiv.org/abs/2311.05931},
	abstract = {Early-exit neural networks (EENNs) enable adaptive and efficient inference by providing predictions at multiple stages during the forward pass. In safety-critical applications, these predictions are meaningful only when accompanied by reliable uncertainty estimates. A popular method for quantifying the uncertainty of predictive models is the use of prediction sets. However, we demonstrate that standard techniques such as conformal prediction and Bayesian credible sets are not suitable for EENNs. They tend to generate non-nested sets across exits, meaning that labels deemed improbable at one exit may reappear in the prediction set of a subsequent exit. To address this issue, we investigate anytime-valid confidence sequences (AVCSs), an extension of traditional confidence intervals tailored for data-streaming scenarios. These sequences are inherently nested and thus well-suited for an EENN's sequential predictions. We explore the theoretical and practical challenges of using AVCSs in EENNs and show that they indeed yield nested sets across exits. Thus our work presents a promising approach towards fast, yet still safe, predictive modeling},
	urldate = {2025-03-05},
	publisher = {arXiv},
	author = {Jazbec, Metod and Forré, Patrick and Mandt, Stephan and Zhang, Dan and Nalisnick, Eric},
	month = jun,
	year = {2024},
	note = {arXiv:2311.05931 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/Users/sagar/Zotero/storage/SALMYSME/2311.html:text/html},
}

@misc{wadia_gentle_2024,
	title = {A {Gentle} {Introduction} to {Gradient}-{Based} {Optimization} and {Variational} {Inequalities} for {Machine} {Learning}},
	url = {http://arxiv.org/abs/2309.04877},
	abstract = {The rapid progress in machine learning in recent years has been based on a highly productive connection to gradient-based optimization. Further progress hinges in part on a shift in focus from pattern recognition to decision-making and multi-agent problems. In these broader settings, new mathematical challenges emerge that involve equilibria and game theory instead of optima. Gradient-based methods remain essential -- given the high dimensionality and large scale of machine-learning problems -- but simple gradient descent is no longer the point of departure for algorithm design. We provide a gentle introduction to a broader framework for gradient-based algorithms in machine learning, beginning with saddle points and monotone games, and proceeding to general variational inequalities. While we provide convergence proofs for several of the algorithms that we present, our main focus is that of providing motivation and intuition.},
	urldate = {2025-03-31},
	publisher = {arXiv},
	author = {Wadia, Neha S. and Dandi, Yatin and Jordan, Michael I.},
	month = feb,
	year = {2024},
	note = {arXiv:2309.04877 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/sagar/Zotero/storage/X54Q964B/2309.html:text/html},
}

@misc{berta_rethinking_2025,
	title = {Rethinking {Early} {Stopping}: {Refine}, {Then} {Calibrate}},
	shorttitle = {Rethinking {Early} {Stopping}},
	url = {http://arxiv.org/abs/2501.19195},
	abstract = {Machine learning classifiers often produce probabilistic predictions that are critical for accurate and interpretable decision-making in various domains. The quality of these predictions is generally evaluated with proper losses like cross-entropy, which decompose into two components: calibration error assesses general under/overconfidence, while refinement error measures the ability to distinguish different classes. In this paper, we provide theoretical and empirical evidence that these two errors are not minimized simultaneously during training. Selecting the best training epoch based on validation loss thus leads to a compromise point that is suboptimal for both calibration error and, most importantly, refinement error. To address this, we introduce a new metric for early stopping and hyperparameter tuning that makes it possible to minimize refinement error during training. The calibration error is minimized after training, using standard techniques. Our method integrates seamlessly with any architecture and consistently improves performance across diverse classification tasks.},
	urldate = {2025-03-31},
	publisher = {arXiv},
	author = {Berta, Eugène and Holzmüller, David and Jordan, Michael I. and Bach, Francis},
	month = jan,
	year = {2025},
	note = {arXiv:2501.19195 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/Users/sagar/Zotero/storage/P7EXMP8T/2501.html:text/html},
}
